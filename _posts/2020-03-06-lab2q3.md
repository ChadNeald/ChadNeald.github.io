---
layout: post
title: False Positives and False Negatives in the World of Machine Learning
subtitle: DSCI 542 Lab2 Exercise 3
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/mds.png
---

## False Positives and False Negatives in the World of Machine Learning

Machine learning has been making a name for itself in computer science and statistics for the last few decades, but if it could solve all our problems, it would have already. Things can and will go wrong, and this post is here to help address two common errors in the world of machine learning. Let me begin with an example. 

#### Example: Predicting Cancer

Let's say you are recruited by a research team to study the causes of cancer in patients. Specifically, your team wants to see if you can predict whether a person has cancer based on survey questions and other available medical info. As the newest member of the team, you go out and collect this data for 100 people, some of whom have cancer and some whom do not. The first couple of rows of this over simplistic data set is shown in the image below.

!["cancer data"](../assets/img/cancer_data.png)

Great! You now hand this data off to a machine learning specialist who uses it to create a model from the data. A model is essentially what is being learned from the data. You can think of it as the computer learning what specific values or trends in different columns indicate someone is more likely to have cancer. Once your model is ready, or trained as we say, it can make predictions on whether or not someone new (someone you didn't initially collect data on) has the disease. The benefits of such a model are apparent but in practice, it is rare to create a perfect model.

#### Defining False Positives and False Negatives

When you ask your team whether they have now cracked the cancer code, you hear them mention that the model is doing ok, but there are still too many false negatives. What does this even mean? 

Well, you may have heard of false positives before so let me start there since it is a bit more intuitive to grasp. 

What this cancer model can now do, since it has already been trained on your collected data, is take information from a new patient (their age, whether they smoke, number of doctor visits last year etc.) and predict if the person has cancer. The goal in this context, also known as the **positive** case, is to detect cancer. If your model continuously predicts that every new person has cancer when in fact they don't, it has too many **false positives**. This is an error in your model.

In contrast, a false negative would be when your model says that a person is healthy when in fact, they have cancer. This is a second type of error in your model. Again, having cancer is the positive case, so predicting no cancer would be to predict a negative result. If the person really has cancer though, this is a **false negative** result and one with impactful consequences as we'll talk about later on.  

Below is a common diagram you will see regarding false positives and false negatives. The image is adapted from a similar image posted on the "Phoenix Area Skeptics Society" blog which can be found [here](https://phoenixskeptics.wordpress.com/2013/07/14/false-positives-and-the-base-rate-fallacy/). The other two squares that I haven't mentioned, true positive and true negative, are simply when the model correctly predicts a person has cancer (when they truly do), or correctly predicts a person doesn't have cancer (when they truly don't).

![types of error square](../assets/img/results_square.png)

#### Asking Critical Questions

Why do we care about false positives and false negatives? Imagine your team gives your trained cancer predicting model to a doctor to use and you tell them that your model can correctly identify whether or not patients have cancer 90% of the time. Is 90% good? Bad? Somewhere in between? 

The quality of your model highly depends on the context and use case. 90% may be great in the context of predicting winning lottery numbers, but in the case of cancer detection, this could be a poor result. Moreover, what's happening with the other 10%? Is your model generating more false positives than false negatives or is the reverse true? Do you care one way or the other?

All of these are important questions to ask once you have a model and look at the results coming out of it.

#### The Consequences

With something like cancer detection, I would argue that a model with more false positives is preferable to one with more false negatives. In simpler terms, when the model makes an error, I would rather the error be predicting someone has cancer when they don't as opposed to predicting someone is fine and healthy when in fact they have undiagnosed cancer.

Option one is the lesser of two evils, and in a medical context, being conservative isn't a bad idea when a diagnosis could lead to more tests, and further examination. Option two however, could be detrimental and even fatal if a patient leaves the hospital not to be seen until their next appointment when they should be starting treatment immediately. 

Thankfully, machine learning specialists can train their models to favour one type of error or another depending on the future use of the model.

#### Wrapping Up

Machine learning isn't a perfect science yet and our models are often sprinkled, or doused in some cases, with errors. It is our responsibility as data scientists to understand these errors and the consequences they entail. Hopefully after reading this blog post you have a concrete understanding of what a false positive and a false negative are, or at the very least, a resource you can refer to in the future.